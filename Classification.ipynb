{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUBWnrjCb_n9"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be8C57ypcLQj"
      },
      "source": [
        "trainpath = '/content/drive/MyDrive/DataScienceProjects/Musical/Data/train/data_with_labels.csv'\n",
        "testpath = '/content/drive/MyDrive/DataScienceProjects/Musical/Data/test/data_with_labels.csv'\n",
        "instruments = ['flu', 'gac', 'gel', 'org', 'pia', 'sax', 'vio', 'voi']\n",
        "noinst = 8 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGXJra77cRc3"
      },
      "source": [
        "def get_data_and_labels(filepath):\n",
        "\tdata = np.genfromtxt(filepath,delimiter = ',')\n",
        "\t#X is the feature matrix, y are the labels\n",
        "\tX = data[:,:-1]\n",
        "\ty = data[:,-1]\n",
        "\ty = y.astype('int')\n",
        "\treturn (X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGeCc5D8iWYV"
      },
      "source": [
        "def cross_valid(X, y, K=3, method='logistic', plot_weights=False, hyperparam = 'Lambda', param = np.logspace(-3,3,7)):\n",
        "\t#hyperparam is the parameter to be selected by cross validation\n",
        "\t#parameter is the value of hyperparam\n",
        "\n",
        "\n",
        "\t########################################################################################\n",
        "\t#cross validation for logistic regression\n",
        "\n",
        "\tif method is 'logistic':\n",
        "\t\tnp.random.seed(39103)\n",
        "\t\tL = len(param)\n",
        "\t\t(n,d) = np.shape(X)\n",
        "\t\tweights = np.zeros([nClasses,d,L]) \n",
        "\t\tkf = KFold(n_splits = K, shuffle = True)\n",
        "\t\tvalid_scores = np.zeros([K,L])\n",
        "\n",
        "\t\t#try different regularization params\n",
        "\t\tfor l in range(L):\n",
        "\t\t\t#k fold cross-validation\n",
        "\t\t\tk = 0\n",
        "\t\t\tfor train_index, valid_index in kf.split(X):\n",
        "\t\t\t\t# print(\"TRAIN:\", train_index, \"VALID:\", valid_index)\n",
        "\t\t\t\tX_train, X_valid = X[train_index], X[valid_index]\n",
        "\t\t\t\ty_train, y_valid = y[train_index], y[valid_index]\n",
        "\t\t\t\t#if regularization parameter is to be chosen\n",
        "\t\t\t\tif hyperparam is 'Lambda':\n",
        "\t\t\t\t\tmodel = train_weights(X_train,y_train, method, Lambda=param[l])\n",
        "\t\t\t\tweights[:,:,l] += model.coef_\n",
        "\t\t\t\tpred = model.predict(X_valid)\n",
        "\t\t\t\tvalid_scores[k,l] = model.score(X_valid,y_valid)\n",
        "\t\t\t\tk += 1\n",
        "\t\t\t#average weights over the K folds\n",
        "\t\t\tweights[:,:,l]/=K\n",
        "\n",
        "\t\t# best_param = np.argmax(np.mean(valid_scores, axis = 0))\n",
        "\t\t# print('Best ' + hyperparam, best_param)\n",
        "\t\t# print('Cross validation scores with best '+ hyperparam, valid_scores[:,best_param])\n",
        "\t\t# print('Variance in weights across folds', np.var(weights[:,:,best_param], axis = 0))\n",
        "\n",
        "\n",
        "\t\tif plot_weights:\n",
        "\t\t\tfor n in range(nClasses):\n",
        "\t\t\t\t# plt.figure()\n",
        "\t\t\t\tplt.semilogx(param,weights[n,:,:].T)\n",
        "\t\t\t\tplt.xlabel('Regularization coefficient')\n",
        "\t\t\t\tplt.ylabel('Weights')\n",
        "\t\t\t\tplt.grid(True)\n",
        "\t\t\t\tplt.savefig('../plots/l1_'+str(n))\n",
        "\n",
        "\t\treturn param,valid_scores\n",
        "\t\t\n",
        "\t\t#############################################################################3\n",
        "\t\t#cross validation for SVM \t\t\n",
        "\n",
        "\telif method is 'svm':\n",
        "\t\tall_hyperparams = dict()\n",
        "\t\tHP = len(hyperparam)\n",
        "\t\tfor i in range(HP):\n",
        "\t\t\tall_hyperparams.update({hyperparam[i]:param[i]})\n",
        "\t\t\n",
        "\t\tsvc = svm.SVC(kernel='rbf')\n",
        "\t\tsvm_cv = GridSearchCV(svc, all_hyperparams, cv = K)\n",
        "\t\tmodel = svm_cv.fit(X,y)\n",
        "\t\tvalid_scores = svm_cv.cv_results_['mean_test_score']\n",
        "\t\tbest_score = svm_cv.best_score_\n",
        "\t\tbest_params = svm_cv.best_params_\n",
        "\n",
        "\t\treturn valid_scores,best_score,best_params"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czp5EEykcZhi"
      },
      "source": [
        "def train_weights(X_train,y_train, method='logistic', reg = 'l1', Lambda = 0.1, niter = 1000, C = 1.0 , gamma= 1.0):\n",
        "\n",
        "\tif method is 'logistic':\n",
        "\t\tlr = LogisticRegression(solver='saga',multi_class='multinomial',\\\n",
        "\t\t\tpenalty = reg, C = 1.0/Lambda, max_iter = niter, tol = 0.001)\n",
        "\t\tclf = lr.fit(X_train,y_train)\n",
        "\t\treturn  clf\n",
        "\n",
        "\telif method is 'svm':\n",
        "\t\tsvc = svm.SVC(C = C, kernel='rbf', gamma=gamma)\n",
        "\t\tclf = svc.fit(X_train,y_train)\n",
        "\t\treturn clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgu9Hxjfctr-"
      },
      "source": [
        "def predict(X,y,model):\n",
        "\tpred_labels = model.predict(X)\n",
        "\t# predict_prob = model.predict_proba(X)\n",
        "\tscore = model.score(X, y)\n",
        "\tconf_mat = confusion_matrix(y, pred_labels)\n",
        "\treturn pred_labels,score,conf_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6rlOt5Icvqv"
      },
      "source": [
        "def pipeline(trainpath, testpath, method):\n",
        "\n",
        "\t#get data\n",
        "\tX_train,y_train = get_data_and_labels(trainpath)\n",
        "\n",
        "\t# cross-validate to select regularization parameter for logistic regression\n",
        "\tif method is 'logistic':\n",
        "\t\tLambda, cv_scores = cross_valid(X_train,y_train, method=method, plot_weights = False)\n",
        "\t\tprint('Cross-validation set accuracies', cv_scores,[''])\t\n",
        "\t\tLambda_best = Lambda[1] \n",
        "\t\t# print('Cross validation scores with lambda = 1', cv_scores[:,3])\n",
        "\n",
        "\t\t# train model on whole training set with all features\n",
        "\t\ttrain_model = train_weights(X_train,y_train, method=method, Lambda=Lambda_best)\n",
        "\t\t# print(train_model.coef_)\n",
        "\n",
        "\t\t# reduce model order \n",
        "\t\tsfm = SelectFromModel(train_model, prefit=True)\n",
        "\t\tnew_feature_inds = np.where(sfm.get_support(indices = False) == True)\n",
        "\t\tprint('Remaining feature indices after L1 ', new_feature_inds)\n",
        "\t\tX_train_new = sfm.transform(X_train)\n",
        "\n",
        "\n",
        "\telif method is 'svm':\n",
        "\t\tC_grid = np.logspace(-2,2,5)\n",
        "\t\tgamma_grid = np.logspace(-3,2,6)\n",
        "\t\tscores,best_score,best_params = cross_valid(X_train, y_train, method=method, hyperparam=['C','gamma'],\\\n",
        "\t\t\tparam=[C_grid, gamma_grid])\n",
        "\t\tprint(best_score, best_params)\n",
        "\n",
        "\t\t# train model on whole training set with all features\n",
        "\t\ttrain_model = train_weights(X_train,y_train, method=method,C=best_params['C'],gamma=best_params['gamma'])\n",
        "\t\tprint('Support Vectors are ',train_model.support_vectors_)\n",
        "\n",
        "\t\n",
        "\t#test on data\n",
        "\tX_test,y_test = get_data_and_labels(testpath)\n",
        "\ty_pred, test_score, conf_mat = predict(X_test,y_test,train_model)\n",
        "\tprint('Test set accuracy', test_score)\n",
        "\tprint('Confusion matrix ')\n",
        "\tprint(conf_mat)\n",
        "\tplot_predicted_classes(X_test,y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMYzpE5Fc0tb"
      },
      "source": [
        "def plot_training_error(Xt,yt,method,niter):\n",
        "\tscores = []\n",
        "\titer = np.arange(1,niter,2)\n",
        "\tfor it in iter:\n",
        "\t\tscores.append(train_weights(Xt,yt,method = method, niter=it).score(Xt,yt))\n",
        "\n",
        "\n",
        "\tfig = plt.figure()\n",
        "\tax  = fig.add_subplot(111)\n",
        "\tax.plot(iter,scores,linewidth=2.0)\n",
        "\tplt.xlabel('# iterations')\n",
        "\tplt.ylim([0.94, 1.01])\n",
        "\tplt.grid(True)\n",
        "\tplt.ylabel('Classification accuracy')\n",
        "\tplt.show()\n",
        "\treturn scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6375p9Lrc3-I"
      },
      "source": [
        "def plot_predicted_classes(Xtest,ytest,ypred):\n",
        "\t\n",
        "\t#use SVD to reduce data to two dimensions and look at predicted labels\n",
        "\tclf =TruncatedSVD(n_components=2)\n",
        "\tsvd = clf.fit_transform(Xtest)\n",
        "\tprint('Variance explained by SVs ', clf.explained_variance_ratio_)\n",
        "\tcolors=['r','g','b','k']\n",
        "\n",
        "\tplt.figure()\t\n",
        "\tplt.xlabel('x_1')\n",
        "\tplt.ylabel('x_2')\n",
        "\tplt.grid(True)\n",
        "\n",
        "\t# ax = plt.axes(projection='3d')\n",
        "\t# ax.set_xlabel('x_1')\n",
        "\t# ax.set_ylabel('x_2')\n",
        "\t# ax.set_zlabel('x_3')\n",
        "\t\n",
        "\tfor c in range(nClasses):\n",
        "\t\tplt.plot(svd[ytest==c][:,0],svd[ytest==c][:,1],colors[c]+'+',markersize=10, markeredgewidth=2)\n",
        "\t\t# ax.plot3D(svd[ytest==c][:,0],svd[ytest==c][:,1],svd[ytest==c][:,2],colors[c]+'+',markersize=8)\n",
        "\n",
        "\terrX,errY=svd[ypred!=ytest],ytest[ypred!=ytest]\n",
        "\tfor c in range(nClasses):\n",
        "\t\tplt.plot(errX[errY==c][:,0],errX[errY==c][:,1],colors[c]+'o', markersize=10, markeredgewidth=5)\n",
        "\n",
        "\tplt.legend(instruments, loc = 'lower left')\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKotcS-sc7Ja"
      },
      "source": [
        "def main():\n",
        "\n",
        "\t#Logistic regression\n",
        "\t# pipeline(trainpath, testpath, method='logistic')\n",
        "\t# Xt, yt = get_data_and_labels(trainpath)\n",
        "\t# scores = plot_training_error(Xt,yt,'logistic',150)\n",
        "\n",
        "\t#SVM\n",
        "\tpipeline(trainpath, testpath, method = 'svm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I9WgWoAePQr"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}